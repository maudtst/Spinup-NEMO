import numpy as np
import xarray as xr
import densite
import matplotlib.pyplot as plt
import copy 
import os
import glob

# SUPER LONG PEUT ETRE LE FAIR EN BASH OU ERREUR
def getRestartFiles(path,radical,puzzled=False):# path = "/thredds/idris/work/ues27zx/Restarts/" term = '19141231'
        """
        Get the restart files of the last simulation step

        Parameters:
            path (str): The path to the restarts files  
            radical (str): Radical of the file name 
                           (e.g. for "OCE_CM65-LR-pi-SpinupRef_19141231_00390.nc", it’s "OCE_CM65-LR-pi-SpinupRef_19141231")
            puzzled (bool): Return Complete Restart File (False) or List of windowed files (True)

        Returns:
            list (of str) or str : List of restart puzzled files paths, or unique restart file path
        """
        if puzzled:
            return glob.glob(path+radical+"_*.nc").sorted()
        else:
            try:
                return glob.glob(path+radical+".nc")[0]
            except IndexError:
                print("No Full Restart Found : Use NEMO_REBUILD from NEMO tools if you didn’t do it yet.")
                break

def getMaskFile(maskpath,restart):
        """
        Get the mask file and adapt it to fit the restart file coordinate system.

        Parameters:
            maskpath (str): The path to the mask file, name of the file included.
            restart (xarray.Dataset): The full restart file we are modifying.

        Returns:
            mask (xarray.Dataset) : The mask dataset adapted to the restart file.
        """
    mask    = xr.open_dataset(maskpath,decode_times=False)
    # Harmonizing the structure of mask with that of restart
    mask = mask.swap_dims(dims_dict={"z": "nav_lev","t":"time_counter"})
    mask["time_counter"]=restart["time_counter"]
    return mask

def recordFullRestart(path,radical,restart):
        """
        Record the Modified Full Restart Dataset to a file in the input directory for analysis.

        Parameters:
            path (str): The path to the restart file directory 
            radical (str): Radical of the original restart file name 
                           (e.g. for "OCE_CM65-LR-pi-SpinupRef_19141231_restart_00390.nc", it’s "OCE_CM65-LR-pi-SpinupRef_19141231_restart")
            restart (xarray.Dataset): The full restart file we are modifying.

        Returns:
            str : Recording Completion Message
        """
    restart.to_netcdf(path+"NEW_"radical+".nc")
    print("Restart saved as : "+ path+"NEW_"radical+".nc")
    return "Recording Complete"

def recordPiecedRestart(path,radical,restart):
        """
        Record the Modified Puzzled Restart Datasets to files in the input directory for analysis.
        It is done by iterating on the existing puzzled dataset files, and creating new ones by appending "NEW_" in front of the filename.
        If the user want to overwrite the old files, they will need to do it manually (a 4 line bash script is available).

        Parameters:
            path (str): The path to the restart file directory 
            radical (str): Radical of the original restart file name 
                           (e.g. for "OCE_CM65-LR-pi-SpinupRef_19141231_restart_00390.nc", it’s "OCE_CM65-LR-pi-SpinupRef_19141231_restart")
            restart (xarray.Dataset): The full restart file we are modifying.

        Returns:
            str : Recording Completion Message
        """
    size=len(glob.glob(path+radical+"_*.nc"))
    for index in range(size):
        Restart_NEW=xr.open_dataset(path+radical+"_%04d.nc"%(index))
        x_slice,y_slice = getXYslice(Restart_NEW)
        Restart_NEW["un"]=restart["un"][:,:,y_slice,x_slice]
        Restart_NEW["vn"]=restart["vn"][:,:,y_slice,x_slice]
        Restart_NEW["ub"]=restart["ub"][:,:,y_slice,x_slice]
        Restart_NEW["vb"]=restart["vb"][:,:,y_slice,x_slice]
        Restart_NEW["sn"]=restart["sn"][:,:,y_slice,x_slice]
        Restart_NEW["tn"]=restart["tn"][:,:,y_slice,x_slice]
        Restart_NEW["sb"]=restart["sb"][:,:,y_slice,x_slice]
        Restart_NEW["tb"]=restart["tb"][:,:,y_slice,x_slice]

        Restart_NEW["rhop"]=restart["rhop"][:,:,y_slice,x_slice]

        Restart_NEW["sshn"]=restart["sshn"][:,y_slice,x_slice]
        Restart_NEW["sshb"]=restart["sshb"][:,y_slice,x_slice]
        
        Restart_NEW["ssv_m"]=restart["ssv_m"][:,y_slice,x_slice]
        Restart_NEW["ssu_m"]=restart["ssu_m"][:,y_slice,x_slice]
        Restart_NEW["sst_m"]=restart["sst_m"][:,y_slice,x_slice]
        Restart_NEW["sss_m"]=restart["sss_m"][:,y_slice,x_slice]
        Restart_NEW["ssh_m"]=restart["ssh_m"][:,y_slice,x_slice]
        Restart_NEW["e3t_m"]=restart["e3t_m"][:,y_slice,x_slice]

        Restart_NEW.to_netcdf(path+"NEW_"+radical+"_%04d.nc"%(i))
        print("Restart Piece saved as : "+ path+"NEW_"radical+"_%04d.nc"%(i))
    return "Recording Complete"

def load_predictions(restart,dirpath="/data/mtissot/simus_predicted"):
    """
    Load predicted data from saved NumPy files into the restart array.
    We use the same prediction step for now and before steps (e.g sshn/sshb). 
    We also update the intermediate step surface variables (e.g. sst_m). 

    Returns:
        restart (xarray.Dataset)  with the following primary variables modified :
            ssh    (xarray.DataArray) : ssh sea surface height predictions  - (t,y,x)
            so     (xarray.DataArray) : salinity predictions                - (t,z,y,x)
            thetao (xarray.DataArray) : temperature predictions             - (t,z,y,x)
    """
    ## Loading new SSH in directly affected variables 
    ## (loading zos.npy, selecting last snapshot, then converting to fitting xarray.DataArray, and cleaning the nans) 
    try:
        zos=np.load(dirpath+"/zos.npy")[-1:]
        restart["sshn"] = xr.DataArray(zos, dims=("time_counter", "y", "x"), name="sshn").fillna(0)  
        restart["sshb"] = restart["sshn"].copy()
        restart["ssh_m"] = restart["sshn"].copy()
    except FileNotFoundError:
        print("Couldn’t find a SSH/ZOS prediction file, keeping the original SSH.")
        
    ## Loading new SO in directly affected variables 
    ## (loading so.npy, selecting last snapshot, then converting to fitting xarray.DataArray, and cleaning the nans) 
    try:
        so = np.load(dirpath+"/so.npy")[-1:] 
        restart["sn"] = xr.DataArray(so, dims=("time_counter", "nav_lev","y", "x"), name="sn").fillna(0)  
        restart["sb"] = restart["sn"].copy()
        restart["sss_m"] = restart["sn"].isel(nav_lev=0).copy()
    except FileNotFoundError:
        print("Couldn’t find a SO prediction file, keeping the original SO.")
        
    ## Loading new THETAO in directly affected variables 
    ## (loading thetao.npy, selecting last snapshot, then converting to fitting xarray.DataArray, and cleaning the nans) 
    try:
        thetao=np.load(dirpath+"/thetao.npy")[-1:]
        restart["tn"] = xr.DataArray(thetao, dims=("time_counter", "nav_lev","y", "x"), name="tn").fillna(0)  
        restart["tb"] = restart["tn"].copy()
        restart["sst_m"] = restart["tn"].isel(nav_lev=0).copy()
    except FileNotFoundError:
        print("Couldn’t find a THETAO prediction file, keeping the original THETAO.")

    return restart

def getXYslice(restart):
    """
    Given a Restart Dataset with 'DOMAIN_position_first' and 'DOMAIN_position_last' attributes,
    this function calculates and returns slices for x and y dimensions.

    Parameters:
        restart (xarray.Dataset) : Restart file
        
    Returns
        x_slice (slice dtype=float) : range of x positions
        y_slice (slice dtype=float) : range of y positions
    """
    First   = restart.DOMAIN_position_first  
    Last    = restart.DOMAIN_position_last
    x_slice = slice(First[0]-1,Last[0])
    y_slice = slice(First[1]-1,Last[1])
    return x_slice, y_slice


def toXarray(var,name,dep=True,fillna=True):
    """
    Converts a numpy array into an xarray DataArray and replace nan values by 0 to obtain the same data format as in restart files. 

    Parameters:
        var (numpy array)       : The  array to be converted.
        name (str)              : The name to be assigned to the resulting xarray DataArray.
        dep (bool, optional)    : If True, indicates that the array has a depth dimension.
                                   Defaults to True.
        fillna (bool, optional) : If True, fills NaN values with 0 after conversion.
                                   Defaults to True.

    Returns:
        array (xarray.DataArray): An xarray DataArray object representing the input numpy array.
    """
    if dep:
        if len(np.shape(var))==4:
            array = xr.DataArray(var, dims=("time_counter", "nav_lev", "y", "x"), name=name)
        elif len(np.shape(var))==3:
            array = xr.DataArray(var, dims=("nav_lev", "y", "x"), name=name)
    else:
        if len(np.shape(var))==3:
            array = xr.DataArray(var, dims=("time_counter", "y", "x"), name=name)
        elif len(np.shape(var))==2:
            array = xr.DataArray(var, dims=("y", "x"), name=name)
    return array.fillna(0)

def propagate_pred(restart,mask):
    """
    Update the variables indirectly affected by the prediction on primary variables (e.g. geostrophic velocities and density). 
    

    Parameters:
        restart (xarray.Dataset) : Full Restart file 
        
    Returns:
        restart (xarray.Dataset) : Full Restart file with all variables modified according to the predictions.
    """
    
    ssh=restart.ssh
    thetao=restart.thetao
    so=restart.so

    deptht = get_deptht(ssh,mask)
    rhop_new,_= get_density(thetao,so,deptht,mask.tmask)

    e3t_new = update_e3t(restart,mask)
    u_new = update_u_velocity(restart,mask,e3t_new).fillna(0)
    v_new = update_v_velocity(restart,mask,e3t_new).fillna(0)

    restart["un"]=u_new.copy()
    restart["vn"]=v_new.copy()
    restart["ub"]=u_new.copy()
    restart["vb"]=v_new.copy()
    restart["rhop"]=rhop_new.fillna(0)
    restart["ssv_m"]=v_new.isel(nav_lev=0)
    restart["ssu_m"]=u_new.isel(nav_lev=0)
    restart["e3t_m"]=e3t_new.isel(nav_lev=0).fillna(0)

    return restart



def update_e3t(restart,mask):
    """
    Update e3t_m : the cell thickness of the top layer.
    Get e3t : the cell thickness for all dimensions, we can use e3t to get the new bathymetry and to update u and velocities 
              e3t = e3t_initital * (1+tmask4D*np.expand_dims(np.tile(ssh*ssmask/(bathy+(1-ssmask)),(75,1,1)),axis=0))
    Get deptht : The depth of each cell on grid. we use it to update the density rhop.
    
    Parameters:
        mask (xarray.Dataset) : Mask Dataset containing tmask values
        restart (xarray.Dataset)      : Restart file

    Returns:
        e3t (numpy.ndarray) : Updated array of z-axis cell thicknesses.
    """
    e3t_ini = restart.e3t_ini                                        # initial z axis cell's thickness on grid T - (t,z,y,x)
    ssmask  = mask.tmask.max(dim="nav_lev")       # continent mask                            - (t,y,x)
    bathy   = e3t_ini.sum(dim="nav_lev")                                         # inital Bathymetry                         - (t,y,x)
    ssh     = restart.sshn                                          # Sea Surface Height                        - (t,y,x)
    tmask   = mask.tmask                     # bathy mask on grid T                      - (t,z,y,x)
    e3t     = e3t_ini*(1+ssh*ssmask/(bathy+1-ssmask))       # - (t,y,x)
    return e3t




def get_deptht(restart,mask):
    """
    Calculate the depth of each vertical level on grid T in the 3D grid.

    Parameters:
        restart (xarray.Dataset)     : The dataset containing ocean model variables.
        mask (xarray.Dataset) : The dataset containing mask variables.

    Returns:
        deptht (numpy.array) : The depth of each vertical level.
    """
    ssh=restart.sshn
    e3w_0 = mask.e3w_0 #initial z axis cell's thickness on grid W - (t,z,y,x)
    e3t_0 = mask.e3t_0 #initial z axis cell's thickness on grid T - (t,z,y,x)
    tmask = mask.tmask #grid T continent mask                     - (t,z,y,x)
    ssmask  = tmask[:,0]                                   #bathymetry                                - (t,y,x)
    bathy   = e3t_0.sum(dim="nav_lev")                      #initial condition depth 0                 - (t,z,y,x)
    depth_0 = e3w_0.copy()
    depth_0[:,0] = 0.5 * e3w_0[:,0]                  
    depth_0[:,1:] = depth_0[:,0:1].data + e3w_0[:,1:].cumsum(dim="nav_lev")
    deptht = depth_0 * (1+ssh/(bathy + 1 - ssmask )) * tmask
return deptht

    
def update_rhop(restart,mask):
    """
    Update the rhop variable in the array based on temperature (thetao) and salinity (so).

    Parameters:
        restart (xarray.Dataset) : Restart file
        mask    (xarray.Dataset) : Mask file

    Returns:
        rhop (xarray.DataArray) 
    """
    x_slice,y_slice = getXYslice(array)
    so     = restart['sn']
    thetao = restart['tn']
    tmask  = mask["tmask"][-1:,:,y_slice,x_slice] 
    deptht = get_depth(restart,mask)
    
    rhop, rho_insitu = get_density(thetao,so,deptht,tmask)
    return rhop


def get_density(thetao,so,depth,tmask):
    """
    Compute potential density referenced at the surface and density anomaly.

    Parameters:
        thetao (numpy.array) : Temperature array - (t,z,y,x).
        so (numpy.array)     : Salinity array    - (t,z,y,x).
        depth (numpy.array)  : Depth array       - (t,z,y,x).
        tmask (numpy.array)  : Mask array        - (t,z,y,x).

    Returns:
        tuple: A tuple containing:
            array: Potential density referenced at the surface.
            array: Density anomaly.
    """
    rdeltaS = 32.0
    r1_S0  = 0.875/35.16504
    r1_T0  = 1./40.
    r1_Z0  = 1.e-4
    
    EOS000 = 8.0189615746e+02
    EOS100 = 8.6672408165e+02
    EOS200 = -1.7864682637e+03
    EOS300 = 2.0375295546e+03
    EOS400 = -1.2849161071e+03
    EOS500 = 4.3227585684e+02
    EOS600 = -6.0579916612e+01
    EOS010 = 2.6010145068e+01
    EOS110 = -6.5281885265e+01
    EOS210 = 8.1770425108e+01
    EOS310 = -5.6888046321e+01
    EOS410 = 1.7681814114e+01
    EOS510 = -1.9193502195
    EOS020 = -3.7074170417e+01
    EOS120 = 6.1548258127e+01
    EOS220 = -6.0362551501e+01
    EOS320 = 2.9130021253e+01
    EOS420 = -5.4723692739
    EOS030 = 2.1661789529e+01
    EOS130 = -3.3449108469e+01
    EOS230 = 1.9717078466e+01
    EOS330 = -3.1742946532
    EOS040 = -8.3627885467
    EOS140 = 1.1311538584e+01
    EOS240 = -5.3563304045
    EOS050 = 5.4048723791e-01
    EOS150 = 4.8169980163e-01
    EOS060 = -1.9083568888e-01
    EOS001 = 1.9681925209e+01
    EOS101 = -4.2549998214e+01
    EOS201 = 5.0774768218e+01
    EOS301 = -3.0938076334e+01
    EOS401 = 6.6051753097
    EOS011 = -1.3336301113e+01
    EOS111 = -4.4870114575
    EOS211 = 5.0042598061
    EOS311 = -6.5399043664e-01
    EOS021 = 6.7080479603
    EOS121 = 3.5063081279
    EOS221 = -1.8795372996
    EOS031 = -2.4649669534
    EOS131 = -5.5077101279e-01
    EOS041 = 5.5927935970e-01
    EOS002 = 2.0660924175
    EOS102 = -4.9527603989
    EOS202 = 2.5019633244
    EOS012 = 2.0564311499
    EOS112 = -2.1311365518e-01
    EOS022 = -1.2419983026
    EOS003 = -2.3342758797e-02
    EOS103 = -1.8507636718e-02
    EOS013 = 3.7969820455e-01
    
    zh  = depth * r1_Z0                             # depth
    zt  = thetao * r1_T0                           # temperature
    zs  = np.sqrt(np.abs(so + rdeltaS ) * r1_S0 ) # square root salinity
    ztm = tmask
    
    zn3 = EOS013*zt  + EOS103*zs+EOS003
    zn2 = (EOS022*zt    + EOS112*zs+EOS012)*zt  + (EOS202*zs+EOS102)*zs+EOS002
    zn1 = (((EOS041*zt  + EOS131*zs+EOS031)*zt + (EOS221*zs+EOS121)*zs+EOS021)*zt + ((EOS311*zs+EOS211)*zs+EOS111)*zs+EOS011)*zt   + (((EOS401*zs+EOS301)*zs+EOS201)*zs+EOS101)*zs+EOS001
    zn0 = (((((EOS060*zt   + EOS150*zs+EOS050)*zt   + (EOS240*zs+EOS140)*zs+EOS040)*zt  + ((EOS330*zs+EOS230)*zs+EOS130)*zs+EOS030)*zt    + (((EOS420*zs+EOS320)*zs+EOS220)*zs+EOS120)*zs+EOS020)*zt   + ((((EOS510*zs+EOS410)*zs+EOS310)*zs+EOS210)*zs+EOS110)*zs+EOS010)*zt    + (((((EOS600*zs+EOS500)*zs+EOS400)*zs+EOS300)*zs+EOS200)*zs+EOS100)*zs+EOS000
    
    zn  = ( ( zn3 * zh + zn2 ) * zh + zn1 ) * zh + zn0
    
    rhop = zn0 * ztm         # potential density referenced at the surface             
    rho_insitu = zn * ztm      # density anomaly (masked)
    return rhop, rho_insitu


def plot_density_infos(array,e3t_new,min_=1017):
    """
    Plot density (rhop) information: surface density, density as a function of depth, and the difference in density as a function of depth. 
    The difference provides insights into density errors, particularly where it decreases instead of increasing

    Parameters:
        array (xarray.Dataset) : Restart file contains density informations
        e3t_new (numpy.array)  : Array representing the new z-axis cell thickness : the distance between two grid points.
        min_ (float, optional) : Minimum value for color scale. Defaults to 1017.

    Returns:
        None
    """
    fig, axes = plt.subplots(1, 3, figsize=(18, 4))
    a = axes[0].pcolor(array["rhop"][0,0],vmin=min_)
    fig.colorbar(a, ax=axes[0])
    
    rhop = array['rhop'].where(array["rhop"][0] != 0., np.nan)
    diff_rhop = np.diff(rhop.isel(time_counter=0), axis=0) / e3t_new[0,:-1]
    
    for i in range(array["rhop"].sizes['x']): 
        for j in range(array["rhop"].sizes['y']):
            rhop.isel(time_counter=0, x=i, y=j).plot(ax=axes[1])     
            axes[2].plot(diff_rhop[:,j,i])  
            
    axes[0].set_title('Surface density')
    axes[1].set_title('Density as a function of depth')
    axes[2].set_title('Diff Density as a function of depth')


# FONCTIONNE MAIS A VOIR
def regularize_rho(rho):
    """
    Regularize the rho variable to ensure the density is alway superieur or equal at a lower depth. 
    If the value found at k-1 depth is lower than the value found at k. k-1 value is replaces by k value.

    Parameters:
        rho (numpy.ndarray): Array representing density with dimensions (time, depth, latitude, longitude).

    Returns:
        numpy.ndarray : Regularized array of density.
    """
    t,z,y,x = np.shape(rho)
    for i in range(x):
        for j in range(y):
            for k in range(z-1):
                if rho[0,k,j,i]>rho[0,k+1,j,i]:
                    rho[0,k+1,j,i] = rho[0,k,j,i]
    return rho






def update_u_velocity(restart,mask,e3t_new):  #e3t_new             = maskarray["e3t_0"].values[0,:,y_slice,x_slice]
    """
    Update the v-component velocity array.Meridional

    Parameters:
        restart (xarray.Dataset)     : Restart file.
        mask    (xarray.Dataset)     : Mask dataset.
        e3t_new (numpy.ndarray)      : Updated array of z-axis cell thicknesses.

    Returns:
        None
    """
    un              = restart.un.copy() #initial v velocity of the restart         - (t,z,y,x)
    thetao          = restart.thetao
    so              = restart.so
    deptht          = get_deptht(restart,mask)
    e2t             = mask.e2t     #initial y axis cell's thickness on grid T - (y,x)
    ff_f            = mask.ff_f    #corriolis force                           - (y,x)
    tmask           = mask.tmask
    umask           = mask.umask
    vmask           = mask.vmask
        
    _,rho_insitu = get_density(thetao,so,deptht,tmask) 
    rho_insitu  = rho_insitu.where(tmask)   #updated density                           - (t,z,y,x)
        
    ind_prof_u=(umask.argmin(dim="nav_lev")-1)*umask.isel(nav_lev=0)

    diff_y = rho_insitu.roll(y=-1) - rho_insitu                #                - (t,z,y,x)
    u_new  = 9.81/ff_f * (diff_y/rho_insitu*e3t_new/e2t).cumsum(dim="nav_lev")
    u_new = u_new - u_new.isel(nav_lev=ind_prof_u)
    un_new = add_bottom_velocity(un,u_new,umask[0])          # add V_0        - (t,z,y,x)
 
    return un_new

def update_v_velocity(array,mask,e3t_new):  #e3t_new             = maskarray["e3t_0"].values[0,:,y_slice,x_slice]
    """
    Update the v-component velocity array.Meridional

    Parameters:
        array (xarray.Dataset)     : Restart file.
        maskarray (xarray.Dataset) : Mask dataset.
        e3t_new (numpy.ndarray)    : Updated array of z-axis cell thicknesses.

    Returns:
        New v_velocity
    """
    vn              = restart.vn.copy() #initial v velocity of the restart         - (t,z,y,x)
    thetao          = restart.thetao
    so              = restart.so
    deptht          = get_deptht(restart,mask)
    e1t             = mask.e1t     #initial y axis cell's thickness on grid T - (y,x)
    ff_f            = mask.ff_f    #corriolis force                           - (y,x)
    tmask           = mask.tmask
    vmask           = mask.vmask
        
    _,rho_insitu = get_density(thetao,so,deptht,tmask) 
    rho_insitu  = rho_insitu.where(tmask)   #updated density                           - (t,z,y,x)
        
    ind_prof_v=(vmask.argmin(dim="nav_lev")-1)*vmask.isel(nav_lev=0)

    diff_x = -rho_insitu.roll(x=1) + rho_insitu                #                - (t,z,y,x)
    v_new  = 9.81/ff_f * (diff_x/rho_insitu*e3t_new/e1t).cumsum(dim="nav_lev") # v without V_0  - (t,z,y,x) C: On intègre vers le fond puis on retire la valeur au fond sur toute la colonne pour avoir v_fond=vo
    v_new = v_new - v_new.isel(nav_lev=ind_prof_v)
    vn_new = add_bottom_velocity(vn,v_new,vmask[0])
        
    return vn_new



def add_bottom_velocity(v_restart,v_update,mask):
    """
    Add bottom velocity values to the updated velocity array.

    Parameters:
        v_restart (numpy.array) : Restart velocity array                           - (t,z,y,x)
        v_update (numpy.array)  : New velocity array without the initial condition - (t,z,y,x)
        mask (numpy.array)      : Mask array indicating presence of water cells    - (z,y,x)

    Returns:
        v_restart (numpy.array): Velocity array with bottom velocity values added.
    """
    ind_prof=(mask.argmin(dim="nav_lev")-1)*mask.isel(nav_lev=0)
    v_fond=v_restart.isel(nav_lev=ind_prof,time_counter=0)
    mask_nan_update = np.isnan(v_update)
    v_new  = mask_nan_update * v_restart + (1-mask_nan_update) * (v_fond + v_update)
    return v_restart
